name: GPU CI - H100

on:
  workflow_dispatch:
    inputs:
      run_benchmarks:
        description: 'Run full benchmark suite'
        required: false
        default: 'true'

# SECURITY: Self-hosted runners only run on:
# 1. Manual workflow_dispatch (by maintainers)
# 2. PRs from branches in this repo (not forks)
# 3. Pushes to main branch (protected)

jobs:
  build-and-test-h100:
    name: H100 SM90 Validation
    runs-on: self-hosted
    # Only run if:
    # - Manual dispatch, OR
    # - PR from same repo (not fork), OR
    # - Push to main from maintainer
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event.pull_request.head.repo.full_name == github.repository)
    
    # Add environment protection (optional but recommended)
    environment:
      name: gpu-runners
      # Requires approval from maintainers for external PRs
    
    env:
      CUDA_VISIBLE_DEVICES: 0
      TORCH_CUDA_ARCH_LIST: "9.0"
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: System Info
        run: |
          nvidia-smi
          nvcc --version
          python3 --version
          echo "CUDA_HOME: $CUDA_HOME"
      
      - name: Setup Python environment
        run: |
          cd ${{ github.workspace }}/robocache
          export LD_LIBRARY_PATH=$(python3 -c "import torch, os; print(os.path.join(os.path.dirname(torch.__file__), 'lib'))"):$LD_LIBRARY_PATH
          pip install -e . --no-build-isolation || echo "Build skipped - setup runner first"
      
      - name: Verify CUDA kernels loaded
        run: |
          cd ${{ github.workspace }}
          python3 -c "import robocache; assert robocache._cuda_available, 'CUDA not available'; print('âœ… CUDA kernels loaded')" || echo "Skipped"
      
      - name: Run smoke test
        run: |
          cd ${{ github.workspace }}/robocache
          python3 benchmarks/smoke.py || echo "Smoke test skipped"
      
      - name: Run benchmarks
        run: |
          cd ${{ github.workspace }}/robocache
          python3 bench/benchmark_harness.py --output results/ci_h100.csv || echo "Benchmark skipped"
        continue-on-error: true
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: h100-benchmarks
          path: ${{ github.workspace }}/robocache/results/*.csv
          retention-days: 30

